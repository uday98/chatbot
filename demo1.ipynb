{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2be31c1-de04-478c-b312-0c7b6b377104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61cee23c-46bd-4fd5-9a1d-d88be2fae9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2081e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index qdrant_client torch transformers\n",
    "!pip install llama-index-embeddings-huggingface\n",
    "\n",
    "!pip install llama-index-llms-ollama\n",
    "\n",
    "!pip install llama-index-vector-stores-qdrant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff299b1-e5a1-4e13-bc87-57e3e051c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdrant_client\n",
    "\n",
    "collection_name=\"demo2\"\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    host=\"localhost\",\n",
    "    port=6333\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd24d9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qdrant_client.qdrant_client.QdrantClient at 0x223925121b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe50862f-7c36-4aea-9bb8-81221f7d5b33",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Directory ./docs does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryReader\n\u001b[0;32m      3\u001b[0m input_dir_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./docs\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleDirectoryReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_dir_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequired_exts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m docs \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_data()\n",
      "File \u001b[1;32mc:\\Users\\Uday Talwar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\llama_index\\core\\readers\\file\\base.py:272\u001b[0m, in \u001b[0;36mSimpleDirectoryReader.__init__\u001b[1;34m(self, input_dir, input_files, exclude, exclude_hidden, errors, recursive, encoding, filename_as_id, required_exts, file_extractor, num_files_limit, file_metadata, raise_on_error, fs)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_dir:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39misdir(input_dir):\n\u001b[1;32m--> 272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dir \u001b[38;5;241m=\u001b[39m _Path(input_dir)\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude \u001b[38;5;241m=\u001b[39m exclude\n",
      "\u001b[1;31mValueError\u001b[0m: Directory ./docs does not exist."
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "input_dir_path = './docs'\n",
    "\n",
    "loader = SimpleDirectoryReader(\n",
    "            input_dir = input_dir_path,\n",
    "            required_exts=[\".pdf\"],\n",
    "            recursive=True\n",
    "        )\n",
    "docs = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa4eed94-dd20-4f64-87ad-a99223f70d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d88ab874-ac08-48ed-ae4a-93c13cdd77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=128\n",
    ")\n",
    "\n",
    "def create_index(documents):\n",
    "    service_context = ServiceContext.from_defaults(node_parser=node_parser)\n",
    "    vector_store = QdrantVectorStore(client=client, collection_name=collection_name)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        storage_context=storage_context,\n",
    "        service_context=service_context\n",
    "    )\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c6756f1a-0819-4496-b87d-b54386ac122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings, VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Initialize embedding model\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Update settings\n",
    "Settings.embed_model = embed_model\n",
    "Settings.node_parser = node_parser\n",
    "\n",
    "def create_index(documents):\n",
    "    vector_store = QdrantVectorStore(\n",
    "        client=client, \n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        vector_store=vector_store\n",
    "    )\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        storage_context=storage_context\n",
    "    )\n",
    "    return index\n",
    "\n",
    "# Create the index\n",
    "index = create_index(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7ba3987-6672-4fd0-abc5-5a270a46a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPEN-AI-API-KEY-HERE\"  # Replace with your actual OpenAI API key\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo\",  # OpenAI model\n",
    "    temperature=0.7,\n",
    "    max_tokens=512\n",
    ")\n",
    "\n",
    "# Update the global settings\n",
    "from llama_index.core import Settings\n",
    "Settings.llm = llm\n",
    "# from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# llm = Ollama(model=\"llama3.2:1b\", request_timeout=120.0)\n",
    "\n",
    "# Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "66c87389-22eb-45a7-80d8-86e5127bcd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=512\n",
    ")\n",
    "\n",
    "# Update the global settings\n",
    "from llama_index.core import Settings\n",
    "Settings.llm = llm\n",
    "\n",
    "# Create the reranker\n",
    "rerank = SentenceTransformerRerank(\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", \n",
    "    top_n=3\n",
    ")\n",
    "\n",
    "# Create the query engine\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[rerank]\n",
    ")\n",
    "\n",
    "# Define the prompt template\n",
    "template = \"\"\"Context information is below:\n",
    "              ---------------------\n",
    "              {context_str}\n",
    "              ---------------------\n",
    "              Based on the context above, analyze the query and provide the response in the following format:\n",
    "              \n",
    "              Scenario: [Describe the situation from matching context]\n",
    "              Remediation: [Provide specific prevention/remediation steps]\n",
    "              Points of contact: [List relevant contact information/helplines]\n",
    "              \n",
    "              If no relevant information is found in the context, respond with \"No matching scenario found.\"\n",
    "              \n",
    "              Query: {query_str}\n",
    "              \n",
    "              Response:\"\"\"\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(template)\n",
    "\n",
    "# Update query engine with new template\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2aa7caba-6525-4e84-a4ce-cd02b806e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "rerank = SentenceTransformerRerank(\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", \n",
    "    top_n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe16fdd2-c7d8-4ca0-af98-010bf8f27b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import get_response_synthesizer\n",
    "\n",
    "# query_engine = index.as_query_engine(\n",
    "#     similarity_top_k=10,\n",
    "#     node_postprocessors=[rerank]\n",
    "# )\n",
    "\n",
    "# def print_source_nodes(response):\n",
    "#     source_nodes = response.source_nodes\n",
    "#     print(\"\\nRetrieved chunks:\")\n",
    "#     for i, node in enumerate(source_nodes):\n",
    "#         print(f\"\\nChunk {i+1}:\")\n",
    "#         print(node.text)\n",
    "\n",
    "# response = query_engine.query(\"Got message about cryptocurrency investment with guaranteed returns. What are the Points of Contact?\")\n",
    "# # print_source_nodes(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2447441c-1e6c-4da2-b98a-2f3abc69e7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RAG DEBUG INFORMATION\n",
      "==================================================\n",
      "\n",
      "User Query:\n",
      "--------------------------------------------------\n",
      "Got an email regarding an investment scheme promising 50% returns in 3 months via WhatsApp\n",
      "\n",
      "Retrieving chunks from Vector DB...\n",
      "Time taken for Vector Search: 5.590 seconds\n",
      "\n",
      "Context being sent to OpenAI:\n",
      "--------------------------------------------------\n",
      "\n",
      "Chunk 1:\n",
      "Scenario  1:  I  received  an  email  stating  that  I  won  a  lottery.  I  am  being  asked  to  provide  \n",
      "documents.\n",
      " Remediation:  Do  not  respond  to  the  email  or  share  any  documents.  This  is  a  classic  lottery  \n",
      "scam\n",
      " \n",
      "attempting\n",
      " \n",
      "to\n",
      " \n",
      "steal\n",
      " \n",
      "your\n",
      " \n",
      "information.\n",
      " Points  of  contact:  Cyber  Crime  Portal  (cybercrime.gov.in)  or  call  National  Cybercrime  Helpline  \n",
      "1930\n",
      "  Scenario  2:  Someone  called  claiming  to  be  from  my  bank  requesting  my  OTP  to  update  KYC.  Remediation:  Banks  never  ask  for  OTP  over  phone.  Never  share  OTP/PIN/CVV  with  anyone.  Points  of  contact:  File  complaint  with  local  cyber  police  station  and  call  bank's  official  fraud  \n",
      "helpline\n",
      "  Scenario  3:  Received  SMS  about  my  bank  account  being  blocked,  asking  to  click  a  link.  Remediation:  Don't  click  on  suspicious  links.  Access  your  bank  account  directly  through  official  \n",
      "website/app.\n",
      " Points  of  contact:  Report  to  National  Cyber  Crime  Reporting  Portal  or  call  1930   Scenario  4:  Got  investment  scheme  promising  50%  returns  in  3  months  via  WhatsApp.  Remediation:  Avoid  unrealistic  investment  schemes.  Verify  with  SEBI  registered  advisors.  Points  of  contact:  SEBI  toll  free  helpline  1800  22  7575   Scenario  5:  Someone  called  pretending  to  be  tech  support  saying  my  computer  is  infected.  Remediation:  Don't  allow  remote  access  to  your  computer.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Chunk 2:\n",
      "Scenario  1:  I  received  an  email  stating  that  I  won  a  lottery.  I  am  being  asked  to  provide  \n",
      "documents.\n",
      " Remediation:  Do  not  respond  to  the  email  or  share  any  documents.  This  is  a  classic  lottery  \n",
      "scam\n",
      " \n",
      "attempting\n",
      " \n",
      "to\n",
      " \n",
      "steal\n",
      " \n",
      "your\n",
      " \n",
      "information.\n",
      " Points  of  contact:  Cyber  Crime  Portal  (cybercrime.gov.in)  or  call  National  Cybercrime  Helpline  \n",
      "1930\n",
      "  Scenario  2:  Someone  called  claiming  to  be  from  my  bank  requesting  my  OTP  to  update  KYC.  Remediation:  Banks  never  ask  for  OTP  over  phone.  Never  share  OTP/PIN/CVV  with  anyone.  Points  of  contact:  File  complaint  with  local  cyber  police  station  and  call  bank's  official  fraud  \n",
      "helpline\n",
      "  Scenario  3:  Received  SMS  about  my  bank  account  being  blocked,  asking  to  click  a  link.  Remediation:  Don't  click  on  suspicious  links.  Access  your  bank  account  directly  through  official  \n",
      "website/app.\n",
      " Points  of  contact:  Report  to  National  Cyber  Crime  Reporting  Portal  or  call  1930   Scenario  4:  Got  investment  scheme  promising  50%  returns  in  3  months  via  WhatsApp.  Remediation:  Avoid  unrealistic  investment  schemes.  Verify  with  SEBI  registered  advisors.  Points  of  contact:  SEBI  toll  free  helpline  1800  22  7575   Scenario  5:  Someone  called  pretending  to  be  tech  support  saying  my  computer  is  infected.  Remediation:  Don't  allow  remote  access  to  your  computer.\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Chunk 3:\n",
      "Remediation:  Avoid  unrealistic  investment  schemes.  Verify  with  SEBI  registered  advisors.  Points  of  contact:  SEBI  toll  free  helpline  1800  22  7575   Scenario  5:  Someone  called  pretending  to  be  tech  support  saying  my  computer  is  infected.  Remediation:  Don't  allow  remote  access  to  your  computer.  Legitimate  tech  support  won't  call  \n",
      "unsolicited.\n",
      " Points  of  contact:  File  FIR  at  local  police  station  and  report  to  cert-in.org.in   Scenario  6:  Received  job  offer  requiring  payment  for  registration/training.  Remediation:  Legitimate  employers  don't  ask  for  money.  Research  company  thoroughly  before  \n",
      "proceeding.\n",
      " Points  of  contact:  Report  to  Ministry  of  Labour  &  Employment  portal  (labour.gov.in)   Scenario  7:  Dating  profile  asking  to  transfer  money  for  emergency/travel  expenses.  Remediation:  Never  send  money  to  online  romantic  interests.  These  are  romance  scams.  Points  of  contact:  Women's  Helpline  1091  or  Cyber  Crime  Helpline  1930   Scenario  8:  Received  call  about  winning  a  lucky  draw  from  online  shopping  site.  Remediation:  Legitimate  e-commerce  sites  don't  conduct  lucky  draws  via  phone.  Hang  up  \n",
      "immediately.\n",
      " Points  of  contact:  Report  to  Consumer  Affairs  helpline  1915   Scenario  9:  Got  message  about  cryptocurrency  investment  with  guaranteed  returns.  Remediation:  Avoid  unregulated  crypto  schemes.  Only  invest  through  legitimate  exchanges.  Points  of  contact:  RBI  Customer  Care  14440  or  Cyber  Crime  Helpline  1930\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Chunk 4:\n",
      "Remediation:  Avoid  unrealistic  investment  schemes.  Verify  with  SEBI  registered  advisors.  Points  of  contact:  SEBI  toll  free  helpline  1800  22  7575   Scenario  5:  Someone  called  pretending  to  be  tech  support  saying  my  computer  is  infected.  Remediation:  Don't  allow  remote  access  to  your  computer.  Legitimate  tech  support  won't  call  \n",
      "unsolicited.\n",
      " Points  of  contact:  File  FIR  at  local  police  station  and  report  to  cert-in.org.in   Scenario  6:  Received  job  offer  requiring  payment  for  registration/training.  Remediation:  Legitimate  employers  don't  ask  for  money.  Research  company  thoroughly  before  \n",
      "proceeding.\n",
      " Points  of  contact:  Report  to  Ministry  of  Labour  &  Employment  portal  (labour.gov.in)   Scenario  7:  Dating  profile  asking  to  transfer  money  for  emergency/travel  expenses.  Remediation:  Never  send  money  to  online  romantic  interests.  These  are  romance  scams.  Points  of  contact:  Women's  Helpline  1091  or  Cyber  Crime  Helpline  1930   Scenario  8:  Received  call  about  winning  a  lucky  draw  from  online  shopping  site.  Remediation:  Legitimate  e-commerce  sites  don't  conduct  lucky  draws  via  phone.  Hang  up  \n",
      "immediately.\n",
      " Points  of  contact:  Report  to  Consumer  Affairs  helpline  1915   Scenario  9:  Got  message  about  cryptocurrency  investment  with  guaranteed  returns.  Remediation:  Avoid  unregulated  crypto  schemes.  Only  invest  through  legitimate  exchanges.  Points  of  contact:  RBI  Customer  Care  14440  or  Cyber  Crime  Helpline  1930\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Chunk 5:\n",
      "Scenario  10:  Someone  impersonating  a  relative  asking  for  urgent  money  transfer.  Remediation:  Verify  directly  with  family  member  using  known  contact  number  before  sending  \n",
      "money.\n",
      " Points  of  contact:  District  Cyber  Crime  Unit  or  National  Helpline  1930\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Getting response from OpenAI...\n",
      "Time taken for OpenAI Response: 3.036 seconds\n",
      "\n",
      "Final Response:\n",
      "--------------------------------------------------\n",
      "Scenario: Got investment scheme promising 50% returns in 3 months via WhatsApp\n",
      "Remediation: Avoid unrealistic investment schemes. Verify with SEBI registered advisors.\n",
      "Points of contact: SEBI toll free helpline 1800 22 7575\n",
      "\n",
      "Timing Summary:\n",
      "--------------------------------------------------\n",
      "Vector Search Time: 5.590 seconds\n",
      "OpenAI Response Time: 3.036 seconds\n",
      "Total Time: 8.646 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "class RAGDebugger:\n",
    "    def __init__(self, query_engine):\n",
    "        self.query_engine = query_engine\n",
    "        self.timings = {}\n",
    "    \n",
    "    def _time_vector_search(self, query):\n",
    "        \"\"\"Time the vector search operation\"\"\"\n",
    "        start = time.time()\n",
    "        # Access the internal retriever to get timing for vector search\n",
    "        retrieved_nodes = self.query_engine._retriever.retrieve(query)\n",
    "        end = time.time()\n",
    "        self.timings['vector_search'] = end - start\n",
    "        return retrieved_nodes\n",
    "\n",
    "    def _time_llm_response(self, query):\n",
    "        \"\"\"Time the LLM (OpenAI) response\"\"\"\n",
    "        start = time.time()\n",
    "        response = self.query_engine.query(query)\n",
    "        end = time.time()\n",
    "        self.timings['llm_response'] = end - start\n",
    "        return response\n",
    "\n",
    "    def print_debug_info(self, user_query):\n",
    "        \"\"\"\n",
    "        Print debug information including timings for each step\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"RAG DEBUG INFORMATION\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # Time the entire process\n",
    "        total_start = time.time()\n",
    "\n",
    "        print(\"\\nUser Query:\")\n",
    "        print(\"-\"*50)\n",
    "        print(user_query)\n",
    "\n",
    "        # Time vector search\n",
    "        print(\"\\nRetrieving chunks from Vector DB...\")\n",
    "        retrieved_nodes = self._time_vector_search(user_query)\n",
    "        print(f\"Time taken for Vector Search: {self.timings['vector_search']:.3f} seconds\")\n",
    "\n",
    "        print(\"\\nContext being sent to OpenAI:\")\n",
    "        print(\"-\"*50)\n",
    "        for i, node in enumerate(retrieved_nodes):\n",
    "            print(f\"\\nChunk {i+1}:\")\n",
    "            print(f\"{node.node.text.strip()}\")\n",
    "            print(\"\\n\" + \"-\"*30)\n",
    "\n",
    "        # Time LLM response\n",
    "        print(\"\\nGetting response from OpenAI...\")\n",
    "        response = self._time_llm_response(user_query)\n",
    "        print(f\"Time taken for OpenAI Response: {self.timings['llm_response']:.3f} seconds\")\n",
    "\n",
    "        # Calculate total time\n",
    "        total_time = time.time() - total_start\n",
    "        self.timings['total'] = total_time\n",
    "\n",
    "        print(\"\\nFinal Response:\")\n",
    "        print(\"-\"*50)\n",
    "        print(str(response))\n",
    "\n",
    "        print(\"\\nTiming Summary:\")\n",
    "        print(\"-\"*50)\n",
    "        print(f\"Vector Search Time: {self.timings['vector_search']:.3f} seconds\")\n",
    "        print(f\"OpenAI Response Time: {self.timings['llm_response']:.3f} seconds\")\n",
    "        print(f\"Total Time: {self.timings['total']:.3f} seconds\")\n",
    "\n",
    "        return response\n",
    "\n",
    "# Example usage:\n",
    "debugger = RAGDebugger(query_engine)\n",
    "user_query = \"Got an email regarding an investment scheme promising 50% returns in 3 months via WhatsApp\"\n",
    "response = debugger.print_debug_info(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9d481-8571-4590-85a7-cb1a2490a0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
