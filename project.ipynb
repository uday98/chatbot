{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2be31c1-de04-478c-b312-0c7b6b377104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61cee23c-46bd-4fd5-9a1d-d88be2fae9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cff299b1-e5a1-4e13-bc87-57e3e051c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdrant_client\n",
    "\n",
    "collection_name=\"demo1\"\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    host=\"localhost\",\n",
    "    port=6333\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe50862f-7c36-4aea-9bb8-81221f7d5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "input_dir_path = './docs'\n",
    "\n",
    "loader = SimpleDirectoryReader(\n",
    "            input_dir = input_dir_path,\n",
    "            required_exts=[\".pdf\"],\n",
    "            recursive=True\n",
    "        )\n",
    "docs = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa4eed94-dd20-4f64-87ad-a99223f70d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 462e4b62-2cd3-4173-b2ac-0836bca3f270\n",
      "Text: Scenario  1:  I  received  an  email  stating  that  I  won  a\n",
      "lottery.  I  am  being  asked  to  provide   documents.  Remediation:\n",
      "Do  not  respond  to  the  email  or  share  any  documents.  This  is\n",
      "a  classic  lottery   scam   attempting   to   steal   your\n",
      "information.  Points  of  contact:  Cyber  Crime  Portal\n",
      "(cybercrime.gov.in) ...\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d88ab874-ac08-48ed-ae4a-93c13cdd77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=128\n",
    ")\n",
    "\n",
    "def create_index(documents):\n",
    "    service_context = ServiceContext.from_defaults(node_parser=node_parser)\n",
    "    vector_store = QdrantVectorStore(client=client, collection_name=collection_name)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        storage_context=storage_context,\n",
    "        service_context=service_context\n",
    "    )\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6756f1a-0819-4496-b87d-b54386ac122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "                                  trust_remote_code=True)\n",
    "Settings.embed_model = embed_model\n",
    "Settings.node_parser = node_parser\n",
    "\n",
    "def create_index(documents):\n",
    "    vector_store = QdrantVectorStore(client=client, collection_name=collection_name)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(documents,\n",
    "                                          storage_context=storage_context)\n",
    "    return index\n",
    "\n",
    "index = create_index(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7ba3987-6672-4fd0-abc5-5a270a46a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:1b\", request_timeout=120.0)\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66c87389-22eb-45a7-80d8-86e5127bcd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "template = \"\"\"Context information is below:\n",
    "              ---------------------\n",
    "              {context_str}\n",
    "              ---------------------\n",
    "              Based on the context above, analyze the query and provide the response in the following format:\n",
    "              \n",
    "              Scenario: [Describe the situation from matching context]\n",
    "              Remediation: [Provide specific prevention/remediation steps]\n",
    "              Points of contact: [List relevant contact information/helplines]\n",
    "              \n",
    "              If no relevant information is found in the context, respond with \"No matching scenario found.\"\n",
    "              \n",
    "              Query: {query_str}\n",
    "              \n",
    "              Response:\"\"\"\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(template)\n",
    "\n",
    "# Update query engine with new template\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2aa7caba-6525-4e84-a4ce-cd02b806e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "rerank = SentenceTransformerRerank(\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", \n",
    "    top_n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe16fdd2-c7d8-4ca0-af98-010bf8f27b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[rerank]\n",
    ")\n",
    "\n",
    "def print_source_nodes(response):\n",
    "    source_nodes = response.source_nodes\n",
    "    print(\"\\nRetrieved chunks:\")\n",
    "    for i, node in enumerate(source_nodes):\n",
    "        print(f\"\\nChunk {i+1}:\")\n",
    "        print(node.text)\n",
    "\n",
    "response = query_engine.query(\"Received job offer requiring payment for registration/training. What are the points of Contact?\")\n",
    "# print_source_nodes(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "557a311a-2dca-4308-a7bc-d307debc3662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Points of contact for receiving a job offer requiring payment for registration/training are:\n",
       "\n",
       "1. Ministry of Labour & Employment portal (labour.gov.in)\n",
       "2. Report to Consumer Affairs helpline (1915) or Cyber Crime Helpline (1930)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9d481-8571-4590-85a7-cb1a2490a0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
